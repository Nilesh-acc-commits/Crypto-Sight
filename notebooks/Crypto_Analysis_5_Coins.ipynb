{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ML-Driven-Web-Platform-for-Cryptocurrency-Price-Forecasting - 5 Coins\n",
                "## Coins: ADA, BNB, BTC, DOGE, ETH\n",
                "This notebook fetches historical data from Binance, calculates technical indicators, and prepares the data for Machine Learning."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Imports and Data Fetching Function\n",
                "This cell imports necessary libraries (`pandas`, `requests`, etc.) and defines the `get_binance_ohlcv` function.\n",
                "- **`get_binance_ohlcv`**: Connects to the Binance API to download historical OHLCV (Open, High, Low, Close, Volume) data for a given symbol and time range. It handles pagination (fetching 1000 rows at a time) to get the full history."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import requests\n",
                "import time\n",
                "import os\n",
                "\n",
                "# Create data directory if it doesn't exist\n",
                "os.makedirs('data', exist_ok=True)\n",
                "\n",
                "def get_binance_ohlcv(symbol, interval, start_time, end_time):\n",
                "    url = \"https://api.binance.com/api/v3/klines\"\n",
                "    all_data = []\n",
                "    start = start_time\n",
                "\n",
                "    while True:\n",
                "        params = {\n",
                "            \"symbol\": symbol,\n",
                "            \"interval\": interval,\n",
                "            \"startTime\": start,\n",
                "            \"endTime\": end_time,\n",
                "            \"limit\": 1000\n",
                "        }\n",
                "        try:\n",
                "            response = requests.get(url, params=params)\n",
                "            if response.status_code != 200:\n",
                "                print(f\"Error fetching data for {symbol}: {response.text}\")\n",
                "                break\n",
                "            data = response.json()\n",
                "        except Exception as e:\n",
                "            print(f\"Exception fetching data for {symbol}: {e}\")\n",
                "            break\n",
                "            \n",
                "        if not data:\n",
                "            break\n",
                "        all_data.extend(data)\n",
                "        start = data[-1][0] + 1\n",
                "        time.sleep(0.2)\n",
                "\n",
                "    if not all_data:\n",
                "        return pd.DataFrame()\n",
                "\n",
                "    df = pd.DataFrame(all_data, columns=[\n",
                "        \"open_time\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"close_time\",\n",
                "        \"quote_asset_volume\",\"trades\",\"taker_buy_volume\",\n",
                "        \"taker_buy_quote_volume\",\"ignore\"\n",
                "    ])\n",
                "\n",
                "    df[\"open_time\"] = pd.to_datetime(df[\"open_time\"], unit='ms')\n",
                "    df[\"close_time\"] = pd.to_datetime(df[\"close_time\"], unit='ms')\n",
                "    for col in [\"open\",\"high\",\"low\",\"close\",\"volume\"]:\n",
                "        df[col] = df[col].astype(float)\n",
                "\n",
                "    if \"ignore\" in df.columns:\n",
                "        df = df.drop(columns=[\"ignore\"])\n",
                "\n",
                "    return df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Data Processing & Feature Engineering Function\n",
                "This cell defines the `process_coin` function, which is the core logic of the notebook.\n",
                "- **Fetches Data**: Calls `get_binance_ohlcv` to get data from Jan 2020 to Jan 2025.\n",
                "- **Calculates Indicators**: Computes technical indicators like SMA, EMA, RSI, MACD, Bollinger Bands, and OBV.\n",
                "- **Generates ML Features**: Creates lagged features (past values) and rolling volatility to help machine learning models predict future movements.\n",
                "- **Saves Data**: Exports the final processed DataFrame to a CSV file in the `data/` folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_coin(symbol_name, ticker):\n",
                "    print(f\"Processing {symbol_name} ({ticker})...\")\n",
                "    \n",
                "    # Parameters\n",
                "    interval = \"1h\"\n",
                "    start = int(pd.Timestamp(\"2020-01-01\").timestamp() * 1000)\n",
                "    end   = int(pd.Timestamp(\"2025-01-01\").timestamp() * 1000)\n",
                "    \n",
                "    # Fetch Data\n",
                "    df = get_binance_ohlcv(ticker, interval, start, end)\n",
                "    \n",
                "    if df.empty:\n",
                "        print(f\"No data found for {ticker}\")\n",
                "        return\n",
                "        \n",
                "    print(f\"Fetched {len(df)} rows for {ticker}\")\n",
                "\n",
                "    # Technical Indicators\n",
                "    df['SMA_20'] = df['close'].rolling(20).mean()\n",
                "    df['EMA_20'] = df['close'].ewm(span=20, adjust=False).mean()\n",
                "\n",
                "    # RSI\n",
                "    delta = df['close'].diff()\n",
                "    gain = delta.clip(lower=0)\n",
                "    loss = -1 * delta.clip(upper=0)\n",
                "    avg_gain = gain.rolling(14).mean()\n",
                "    avg_loss = loss.rolling(14).mean()\n",
                "    rs = avg_gain / avg_loss\n",
                "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
                "\n",
                "    # MACD\n",
                "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
                "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
                "    df['MACD'] = ema12 - ema26\n",
                "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
                "\n",
                "    # Bollinger Bands\n",
                "    df['BBM'] = df['close'].rolling(20).mean()\n",
                "    df['BBU'] = df['BBM'] + 2 * df['close'].rolling(20).std()\n",
                "    df['BBL'] = df['BBM'] - 2 * df['close'].rolling(20).std()\n",
                "\n",
                "    # OBV\n",
                "    df['OBV'] = ( (df['close'].diff() > 0) * df['volume']).cumsum() - ((df['close'].diff() < 0) * df['volume']).cumsum()\n",
                "\n",
                "    # ML Features (Lag Features, Returns, Volatility)\n",
                "    # Lagged close\n",
                "    for lag in [1, 3, 6, 12, 24]:\n",
                "        df[f'close_lag_{lag}'] = df['close'].shift(lag)\n",
                "\n",
                "    # Lagged volume\n",
                "    for lag in [1, 3, 6, 12, 24]:\n",
                "        df[f'volume_lag_{lag}'] = df['volume'].shift(lag)\n",
                "\n",
                "    # Returns\n",
                "    df['return_1h'] = df['close'].pct_change(1)\n",
                "    df['return_3h'] = df['close'].pct_change(3)\n",
                "    df['return_6h'] = df['close'].pct_change(6)\n",
                "\n",
                "    # Rolling volatility\n",
                "    for window in [3, 6, 12, 24]:\n",
                "        df[f'vol_{window}h'] = df['close'].rolling(window).std()\n",
                "\n",
                "    df['target_next_close'] = df['close'].shift(-1)\n",
                "    df['target_up_down'] = (df['target_next_close'] > df['close']).astype(int)\n",
                "\n",
                "    df = df.dropna().reset_index(drop=True)\n",
                "    \n",
                "    # Clean Data (Remove zeros)\n",
                "    cols_to_check = [\"volume\", \"quote_asset_volume\", \"trades\"]\n",
                "    mask = (df[cols_to_check] == 0).any(axis=1)\n",
                "    if mask.sum() > 0:\n",
                "        print(f\"Removing {mask.sum()} rows with zeros in {cols_to_check}\")\n",
                "        df = df[~mask]\n",
                "\n",
                "    # Save to CSV\n",
                "    output_path = f\"data/{symbol_name}_ML_ready.csv\"\n",
                "    df.to_csv(output_path, index=False)\n",
                "    print(f\"Saved processed data to {output_path}. Shape: {df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Execution for Each Coin\n",
                "The following cells call `process_coin` for each of the 5 selected cryptocurrencies. This triggers the data fetching and processing pipeline for each one."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing ADA (ADAUSDT)...\n",
                        "Fetched 43817 rows for ADAUSDT\n",
                        "Saved processed data to data/ADA_ML_ready.csv. Shape: (43792, 40)\n"
                    ]
                }
            ],
            "source": [
                "# 1. ADA (Cardano)\n",
                "process_coin(\"ADA\", \"ADAUSDT\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing BNB (BNBUSDT)...\n",
                        "Fetched 43817 rows for BNBUSDT\n",
                        "Saved processed data to data/BNB_ML_ready.csv. Shape: (43792, 40)\n"
                    ]
                }
            ],
            "source": [
                "# 2. BNB (Binance Coin)\n",
                "process_coin(\"BNB\", \"BNBUSDT\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing BTC (BTCUSDT)...\n",
                        "Fetched 43817 rows for BTCUSDT\n",
                        "Saved processed data to data/BTC_ML_ready.csv. Shape: (43792, 40)\n"
                    ]
                }
            ],
            "source": [
                "# 3. BTC (Bitcoin)\n",
                "process_coin(\"BTC\", \"BTCUSDT\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing DOGE (DOGEUSDT)...\n",
                        "Fetched 43817 rows for DOGEUSDT\n",
                        "Saved processed data to data/DOGE_ML_ready.csv. Shape: (43792, 40)\n"
                    ]
                }
            ],
            "source": [
                "# 4. DOGE (Dogecoin)\n",
                "process_coin(\"DOGE\", \"DOGEUSDT\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing ETH (ETHUSDT)...\n",
                        "Fetched 43817 rows for ETHUSDT\n",
                        "Saved processed data to data/ETH_ML_ready.csv. Shape: (43792, 40)\n"
                    ]
                }
            ],
            "source": [
                "# 5. ETH (Ethereum)\n",
                "process_coin(\"ETH\", \"ETHUSDT\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
